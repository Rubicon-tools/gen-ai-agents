#!/usr/bin/env python3
"""
Script de diagnostic des requÃªtes RAG
Montre comment le systÃ¨me trouve le contexte pertinent pour chaque question
"""

from qdrant_client import QdrantClient
from modules.embeddings import embed_texts
from modules.generator import generate_response
import json

def debug_query(question: str, show_full_context: bool = False):
    """
    DÃ©bogue une requÃªte en montrant le processus de recherche et de rÃ©cupÃ©ration
    """
    print("ðŸ” DIAGNOSTIC DE REQUÃŠTE RAG")
    print("=" * 50)
    print(f"â“ Question: {question}")
    print()
    
    # 1. Connexion Ã  Qdrant
    client = QdrantClient(host="localhost", port=6333)
    
    # 2. GÃ©nÃ©rer l'embedding de la question
    print("ðŸ§  Ã‰TAPE 1: GÃ©nÃ©ration de l'embedding de la question")
    print("-" * 40)
    
    try:
        question_embedding = embed_texts([question])[0]
        print(f"âœ… Embedding gÃ©nÃ©rÃ©: {len(question_embedding)} dimensions")
        print(f"ðŸ“Š PremiÃ¨res valeurs: {question_embedding[:5]}...")
    except Exception as e:
        print(f"âŒ Erreur lors de la gÃ©nÃ©ration de l'embedding: {e}")
        return
    
    # 3. Rechercher les chunks les plus similaires
    print(f"\nðŸ” Ã‰TAPE 2: Recherche des chunks pertinents")
    print("-" * 40)
    
    try:
        search_results = client.search(
            collection_name="rag_collection",
            query_vector=question_embedding,
            limit=5,  # RÃ©cupÃ©rer top-5 pour l'analyse
            with_payload=True,
            with_vectors=False
        )
        
        print(f"ðŸ“Š Chunks trouvÃ©s: {len(search_results)}")
        print()
        
        # Analyser chaque rÃ©sultat
        relevant_chunks = []
        for i, result in enumerate(search_results):
            score = result.score
            chunk_text = result.payload.get('text', 'Pas de texte')
            chunk_id = result.id
            
            print(f"ðŸ† CHUNK #{i+1} (ID: {chunk_id})")
            print(f"   ðŸ“ˆ Score de similaritÃ©: {score:.4f}")
            print(f"   ðŸ“ Longueur: {len(chunk_text)} caractÃ¨res")
            
            # Analyser la pertinence du chunk
            relevance_analysis = analyze_chunk_relevance(question, chunk_text)
            print(f"   ðŸŽ¯ Pertinence: {relevance_analysis}")
            
            # Afficher un aperÃ§u du chunk
            preview = chunk_text[:150] + "..." if len(chunk_text) > 150 else chunk_text
            print(f"   ðŸ“ AperÃ§u: {preview}")
            
            # DÃ©cider si le chunk est suffisamment pertinent
            if score > 0.3:  # Seuil de pertinence
                relevant_chunks.append(chunk_text)
                print(f"   âœ… CONSERVÃ‰ (score > 0.3)")
            else:
                print(f"   âš ï¸  SCORE TROP FAIBLE")
            
            print()
        
        # 4. Construire le contexte final
        print("ðŸ“‹ Ã‰TAPE 3: Construction du contexte final")
        print("-" * 40)
        
        if relevant_chunks:
            context = "\n\n".join(relevant_chunks)
            print(f"âœ… Contexte construit: {len(relevant_chunks)} chunks pertinents")
            print(f"ðŸ“ Longueur totale du contexte: {len(context)} caractÃ¨res")
            
            if show_full_context:
                print(f"\nðŸ“„ CONTEXTE COMPLET:")
                print("â”€" * 50)
                print(context)
                print("â”€" * 50)
            
            # 5. GÃ©nÃ©rer la rÃ©ponse
            print(f"\nðŸ¤– Ã‰TAPE 4: GÃ©nÃ©ration de la rÃ©ponse")
            print("-" * 40)
            
            try:
                answer = generate_response(relevant_chunks, question)
                print(f"âœ… RÃ©ponse gÃ©nÃ©rÃ©e:")
                print("â”€" * 50)
                print(answer)
                print("â”€" * 50)
                
            except Exception as e:
                print(f"âŒ Erreur lors de la gÃ©nÃ©ration: {e}")
                
        else:
            print("âŒ Aucun chunk suffisamment pertinent trouvÃ©")
            print("ðŸ’¡ Suggestions:")
            print("   â€¢ Reformulez votre question")
            print("   â€¢ Utilisez des mots-clÃ©s du document")
            print("   â€¢ VÃ©rifiez que le document contient l'information")
    
    except Exception as e:
        print(f"âŒ Erreur lors de la recherche: {e}")


def analyze_chunk_relevance(question: str, chunk_text: str) -> str:
    """
    Analyse la pertinence d'un chunk par rapport Ã  une question
    """
    question_lower = question.lower()
    chunk_lower = chunk_text.lower()
    
    # Compter les mots-clÃ©s communs
    question_words = set(question_lower.split())
    chunk_words = set(chunk_lower.split())
    common_words = question_words.intersection(chunk_words)
    
    # Filtrer les mots trop courts
    common_words = {w for w in common_words if len(w) > 3}
    
    if len(common_words) >= 3:
        return f"TRÃˆS PERTINENT ({len(common_words)} mots-clÃ©s: {', '.join(list(common_words)[:3])})"
    elif len(common_words) >= 1:
        return f"PERTINENT ({len(common_words)} mots-clÃ©s: {', '.join(common_words)})"
    else:
        return "PEU PERTINENT (aucun mot-clÃ© commun)"


def interactive_debug():
    """
    Mode interactif pour tester plusieurs questions
    """
    print("ðŸ” MODE DIAGNOSTIC INTERACTIF")
    print("=" * 40)
    print("Tapez vos questions pour analyser le processus RAG")
    print("Commandes: 'quit' pour quitter, 'context' pour voir le contexte complet")
    print()
    
    while True:
        try:
            question = input("â“ Votre question: ").strip()
            
            if not question:
                continue
                
            if question.lower() in ['quit', 'exit', 'q']:
                break
                
            if question.lower() == 'context':
                # Mode avec contexte complet
                debug_query("humanitarian data", show_full_context=True)
                continue
            
            # Mode normal
            debug_query(question, show_full_context=False)
            
            print("\n" + "="*60 + "\n")
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"âŒ Erreur: {e}")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # Mode ligne de commande
        question = " ".join(sys.argv[1:])
        debug_query(question, show_full_context=True)
    else:
        # Mode interactif
        interactive_debug()
